{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102966,"databundleVersionId":12412856,"sourceType":"competition"},{"sourceId":11918623,"sourceType":"datasetVersion","datasetId":7492837}],"dockerImageVersionId":31042,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Team Leader: Yashodip More, Electrical Engineering, RC Patel Institute of Technology, Shirpur, Maharashtra – yashodipmore2004@gmail.com\n#### Team Member: S.M. Sakthivel, AI & Data Science, Achariya College of Engineering Technology, Puducherry – s.m.sakthivelofficial@gmail.com\n#### Team Member: Komal Kumavat, Electrical Engineering, RC Patel Institute of Technology, Shirpur, Maharashtra – komalkumavat025@gmail.com","metadata":{}},{"cell_type":"markdown","source":"# Load Labels and Prepare Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\n# Paths\ntrain_dir = '/kaggle/input/soil-2-data/Soil Classification 2/train'\ntest_dir = '/kaggle/input/soil-2-data/Soil Classification 2/test'\nlabel_file = '/kaggle/input/soil-2-data/Soil Classification 2/train_labels.csv'\n\n# Load labels\ndf = pd.read_csv(label_file)\n\n# Split into train/val\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n\n# Transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n                         std=[0.229, 0.224, 0.225])\n])\n\n# Dataset class\nclass SoilDataset(Dataset):\n    def __init__(self, dataframe, img_dir, transform=None):\n        self.dataframe = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_name = self.dataframe.iloc[idx]['image_id']\n        label = int(self.dataframe.iloc[idx]['label'])\n        img_path = os.path.join(self.img_dir, img_name)\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# Loaders\ntrain_dataset = SoilDataset(train_df, train_dir, transform)\nval_dataset = SoilDataset(val_df, train_dir, transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T09:15:27.411444Z","iopub.execute_input":"2025-05-23T09:15:27.411759Z","iopub.status.idle":"2025-05-23T09:15:43.382497Z","shell.execute_reply.started":"2025-05-23T09:15:27.411738Z","shell.execute_reply":"2025-05-23T09:15:43.381892Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Model Architecture and Training","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models\nfrom sklearn.metrics import f1_score\n\n# Check for GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')\n\n# Load pretrained ResNet18\nmodel = models.resnet18(pretrained=True)\n\n# Modify the final layer to output a single probability\nmodel.fc = nn.Sequential(\n    nn.Linear(model.fc.in_features, 1),\n    nn.Sigmoid()\n)\n\nmodel = model.to(device)\n\n# Loss and optimizer\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T09:16:19.563193Z","iopub.execute_input":"2025-05-23T09:16:19.563693Z","iopub.status.idle":"2025-05-23T09:16:20.702890Z","shell.execute_reply.started":"2025-05-23T09:16:19.563669Z","shell.execute_reply":"2025-05-23T09:16:20.702101Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 144MB/s] \n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"#  Training & Evaluation Loop","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, epochs=10):\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0\n        for images, labels in train_loader:\n            images = images.to(device)\n            labels = labels.float().unsqueeze(1).to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        # Evaluation\n        model.eval()\n        all_preds = []\n        all_targets = []\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images = images.to(device)\n                labels = labels.to(device)\n                outputs = model(images)\n                preds = (outputs > 0.5).int().cpu().numpy()\n                all_preds.extend(preds.flatten())\n                all_targets.extend(labels.cpu().numpy())\n\n        f1 = f1_score(all_targets, all_preds)\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}, Val F1: {f1:.4f}\")\n\ntrain_model(model, train_loader, val_loader, epochs=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T09:16:40.204747Z","iopub.execute_input":"2025-05-23T09:16:40.205014Z","iopub.status.idle":"2025-05-23T09:19:48.143571Z","shell.execute_reply.started":"2025-05-23T09:16:40.204994Z","shell.execute_reply":"2025-05-23T09:19:48.142777Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 7.4676, Val F1: 0.9820\nEpoch 2/10, Loss: 5.2175, Val F1: 0.9799\nEpoch 3/10, Loss: 4.1162, Val F1: 0.9758\nEpoch 4/10, Loss: 4.3309, Val F1: 0.9737\nEpoch 5/10, Loss: 4.1723, Val F1: 0.9799\nEpoch 6/10, Loss: 2.6939, Val F1: 0.9758\nEpoch 7/10, Loss: 2.3075, Val F1: 0.9654\nEpoch 8/10, Loss: 2.3578, Val F1: 0.9696\nEpoch 9/10, Loss: 2.1439, Val F1: 0.9696\nEpoch 10/10, Loss: 2.1301, Val F1: 0.9696\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Test Prediction + Submission File","metadata":{}},{"cell_type":"code","source":"# Load test image IDs\ntest_ids = pd.read_csv('/kaggle/input/soil-2-data/Soil Classification 2/test_ids.csv')\n\n# Define test dataset class\nclass TestSoilDataset(Dataset):\n    def __init__(self, dataframe, img_dir, transform=None):\n        self.dataframe = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_name = self.dataframe.iloc[idx]['image_id']\n        img_path = os.path.join(test_dir, img_name)\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, img_name\n\n# Create dataset and loader\ntest_dataset = TestSoilDataset(test_ids, test_dir, transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Run predictions\nmodel.eval()\npredictions = []\n\nwith torch.no_grad():\n    for images, img_names in test_loader:\n        images = images.to(device)\n        outputs = model(images)\n        preds = (outputs > 0.5).int().cpu().numpy().flatten()\n        for name, pred in zip(img_names, preds):\n            predictions.append({'image_id': name, 'label': pred})\n\n# Save to CSV\nsubmission_df = pd.DataFrame(predictions)\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission file saved as 'submission.csv'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T09:30:52.159562Z","iopub.execute_input":"2025-05-23T09:30:52.160277Z","iopub.status.idle":"2025-05-23T09:30:57.149705Z","shell.execute_reply.started":"2025-05-23T09:30:52.160248Z","shell.execute_reply":"2025-05-23T09:30:57.148883Z"}},"outputs":[{"name":"stdout","text":"Submission file saved as 'submission.csv'\n","output_type":"stream"}],"execution_count":6}]}